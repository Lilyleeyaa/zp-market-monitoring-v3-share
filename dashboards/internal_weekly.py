"""
Internal Weekly Dashboard - ë‚´ë¶€ìš© (ê²½ìŸì‚¬ í¬í•¨)
ë§¤ ì ‘ì† ì‹œ ì§€ë‚œì£¼ ê¸ˆìš”ì¼~ì–´ì œ ëª©ìš”ì¼(7ì¼) ê¸°ì‚¬ ìë™ í¬ë¡¤ë§
"""
import streamlit as st
import pandas as pd
import sys
import os
from datetime import datetime, timedelta
import pytz

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from auth.simple_auth import authenticate

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ZP Market Monitoring - Internal Weekly",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ì¸ì¦ (ë‚´ë¶€ ì „ìš©)
email, access_level = authenticate(mode='weekly')

if access_level != 'internal':
    st.error("âŒ ì´ ëŒ€ì‹œë³´ë“œëŠ” ë‚´ë¶€ ì‚¬ìš©ìë§Œ ì ‘ê·¼ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    st.stop()

# ====================
# ë™ì  ë‚ ì§œ ê³„ì‚°
# ====================
def get_weekly_date_range():
    """
    ì§€ë‚œì£¼ ê¸ˆìš”ì¼ ~ ì–´ì œ ëª©ìš”ì¼ (7ì¼)
    ê¸ˆìš”ì¼ì— ì ‘ì†í•˜ë©´ ì§€ë‚œì£¼ ê¸ˆ~ì´ë²ˆì£¼ ëª© ê¸°ì‚¬
    """
    kst = pytz.timezone('Asia/Seoul')
    today = datetime.now(kst)
    
    # ì–´ì œ
    yesterday = today - timedelta(days=1)
    
    # ì§€ë‚œì£¼ ê¸ˆìš”ì¼ (7ì¼ ì „)
    last_friday = today - timedelta(days=7)
    
    return last_friday, yesterday


# ====================
# CSV ë¡œë”© í•¨ìˆ˜ (GitHub Actions ê²°ê³¼)
# ====================
@st.cache_data(ttl=3600, show_spinner=False)  # 1ì‹œê°„ ìºì‹±
def load_weekly_data():
    """
    GitHub Actionsë¡œ ìƒì„±ëœ Weekly CSV ë¡œë”©
    """
    try:
        import glob
        
        base_dir = "data/articles_raw"
        if not os.path.exists(base_dir):
            base_dir = "../data/articles_raw"
        
        # articles_ranked_YYYYMMDD.csv íŒŒì¼ ì°¾ê¸°
        ranked_files = sorted(glob.glob(os.path.join(base_dir, "articles_ranked_*.csv")))
        
        if not ranked_files:
            return pd.DataFrame(), {}
        
        # ê°€ì¥ ìµœì‹  íŒŒì¼
        latest_file = ranked_files[-1]
        df = pd.read_csv(latest_file, encoding='utf-8-sig')
        
        # ë‚ ì§œ ë³€í™˜
        if 'published_date' in df.columns:
            df['published_date'] = pd.to_datetime(df['published_date']).dt.date
        
        # ì¹´í…Œê³ ë¦¬ í™•ì¸
        if 'category' not in df.columns:
            df['category'] = 'General'
        
        # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
        start_date, end_date = get_weekly_date_range()
        
        info = {
            'start_date': start_date.strftime('%Y-%m-%d'),
            'end_date': end_date.strftime('%Y-%m-%d'),
            'total_articles': len(df),
            'data_file': os.path.basename(latest_file),
            'updated_time': datetime.fromtimestamp(os.path.getmtime(latest_file)).strftime('%Y-%m-%d %H:%M:%S')
        }
        
        return df, info
        
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return pd.DataFrame(), {}


# ====================
# ë©”ì¸ UI
# ====================
st.title("ğŸ“Š ZP Market Monitoring - Internal Weekly")
st.caption(f"ë¡œê·¸ì¸: {email} ({access_level})")

# CSV ë¡œë”© (GitHub Actions ê²°ê³¼)
df, data_info = load_weekly_data()

if df.empty:
    st.warning("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. GitHub Actions í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    st.info("ğŸ’¡ GitHub Repository â†’ Actions íƒ­ì—ì„œ 'Weekly Crawl and Rank' ì›Œí¬í”Œë¡œìš°ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.stop()

# ë°ì´í„° ì •ë³´ í‘œì‹œ
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("í¬ë¡¤ë§ ê¸°ê°„", f"{data_info.get('start_date', 'N/A')} ~ {data_info.get('end_date', 'N/A')}")
with col2:
    st.metric("ì „ì²´ ê¸°ì‚¬", f"{data_info.get('total_articles', 0):,}ê°œ")
with col3:
    st.metric("íŒŒì¼ ì—…ë°ì´íŠ¸", data_info.get('updated_time', 'N/A'))
with col4:
    st.caption(f"ğŸ“ {data_info.get('data_file', 'N/A')}")
    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        st.rerun()

st.markdown("---")

# ====================
# í•„í„° (ì‚¬ì´ë“œë°”)
# ====================
with st.sidebar:
    st.header("ğŸ” í•„í„°")
    
    # ì¹´í…Œê³ ë¦¬ í•„í„°
    categories = ['ì „ì²´'] + sorted(df['category'].unique().tolist())
    selected_category = st.selectbox("ì¹´í…Œê³ ë¦¬", categories)
    
    # ë‚ ì§œ í•„í„°
    if 'published_date' in df.columns:
        date_range = st.date_input(
            "ë°œí–‰ì¼",
            value=(df['published_date'].min(), df['published_date'].max()),
            min_value=df['published_date'].min(),
            max_value=df['published_date'].max()
        )
    
    # ì ìˆ˜ í•„í„° (AI Score)
    min_score = st.slider("ìµœì†Œ AI ì ìˆ˜", 0.0, 1.0, 0.2)

# í•„í„° ì ìš©
filtered_df = df.copy()

if selected_category != 'ì „ì²´':
    filtered_df = filtered_df[filtered_df['category'] == selected_category]

if 'published_date' in filtered_df.columns and len(date_range) == 2:
    filtered_df = filtered_df[
        (filtered_df['published_date'] >= date_range[0]) &
        (filtered_df['published_date'] <= date_range[1])
    ]

if 'score_ag' in filtered_df.columns:
    filtered_df = filtered_df[filtered_df['score_ag'] >= min_score]

# ====================
# ê¸°ì‚¬ ëª©ë¡ í‘œì‹œ
# ====================
st.subheader(f"ğŸ“° ê¸°ì‚¬ ëª©ë¡ ({len(filtered_df):,}ê°œ)")

if filtered_df.empty:
    st.info("í•„í„° ì¡°ê±´ì— ë§ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    if 'score_ag' in filtered_df.columns:
        filtered_df = filtered_df.sort_values('score_ag', ascending=False)
    
    # ê¸°ì‚¬ ì¹´ë“œ í‘œì‹œ
    # ê¸°ì‚¬ ì¹´ë“œ í‘œì‹œ
    for idx, row in filtered_df.iterrows():
        with st.container():
            col1, col2 = st.columns([0.85, 0.15])
            with col1:
                st.markdown(f"### [{row.get('category', 'N/A')}] {row['title']}")
                st.caption(f"{row.get('published_date', 'N/A')} | {row.get('site_name', 'N/A')}")
                st.markdown(f"{row.get('summary', 'N/A')}")
                st.markdown(f"[ğŸ”— ì›ë¬¸ ë³´ê¸°]({row['url']})")
            
            with col2:
                score = row.get('score_ag', 0)
                st.metric("AI ì ìˆ˜", f"{score:.2f}")
                
            st.divider()

# ====================
# í†µê³„
# ====================
st.markdown("---")
st.subheader("ğŸ“Š í†µê³„")

stat_col1, stat_col2, stat_col3 = st.columns(3)

with stat_col1:
    st.markdown("### ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬")
    category_counts = filtered_df['category'].value_counts()
    st.bar_chart(category_counts)

with stat_col2:
    st.markdown("### ì¼ìë³„ ê¸°ì‚¬ ìˆ˜")
    if 'published_date' in filtered_df.columns:
        daily_counts = filtered_df.groupby('published_date').size()
        st.line_chart(daily_counts)

with stat_col3:
    st.markdown("### AI ì ìˆ˜ ë¶„í¬")
    if 'score_ag' in filtered_df.columns:
        st.bar_chart(filtered_df['score_ag'].value_counts().sort_index())

st.markdown("---")
st.caption("ğŸ”’ Internal Only - ëª¨ë“  í‚¤ì›Œë“œ í¬í•¨ (ê²½ìŸì‚¬ í¬í•¨)")
